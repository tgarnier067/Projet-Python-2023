{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Définition du Problème et Objectifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexte et Pertinence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un contexte mondial où la gestion efficace de l'énergie est devenue une priorité cruciale, notre projet vise à analyser la consommation d'énergie par département dans différents secteurs en France. L'objectif est de fournir une compréhension approfondie des modèles de consommation énergétique, qui est essentielle pour orienter les politiques énergétiques, promouvoir la durabilité et optimiser les ressources. Ce projet est particulièrement pertinent étant donné les défis actuels liés au changement climatique et à la transition énergétique. En examinant les données de consommation énergétique à l'échelle des communes, nous pouvons identifier des tendances spécifiques, des anomalies et des opportunités d'amélioration. Cela permettra aux décideurs, aux entreprises et aux consommateurs de prendre des mesures éclairées pour réduire la consommation d'énergie, améliorer l'efficacité énergétique et favoriser l'adoption d'énergies renouvelables. En outre, ce projet contribue à une meilleure compréhension des disparités régionales en matière de consommation d'énergie, offrant ainsi une perspective précieuse pour des interventions ciblées et personnalisées.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectifs du Projet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre projet, au cœur de l'intersection entre technologie, environnement et société, se fixe des objectifs ambitieux et significatifs :\n",
    "\n",
    "**Cartographie de la Consommation Énergétique :** Notre premier objectif est de dresser une carte précise de la consommation d'énergie dans les différents départements français. En mettant en lumière ces données, nous souhaitons offrir une vision claire et détaillée de la répartition énergétique sur le territoire.\n",
    "\n",
    "**Identification des Tendances et Anomalies :** Nous visons à décrypter les tendances sous-jacentes et à détecter d'éventuelles anomalies dans les habitudes de consommation énergétique. Cela permettra de comprendre les pratiques énergétiques actuelles et d'identifier les zones à haut potentiel d'amélioration.\n",
    "\n",
    "**Analyse Comparative par Secteur :** Un autre objectif crucial est de comparer la consommation énergétique entre différents secteurs (résidentiel, industriel, commercial, etc.). Cela aidera à cerner les secteurs les plus énergivores et à envisager des stratégies d'optimisation.\n",
    "\n",
    "**Prédiction des Tendances Futures :** Nous ambitionnons de développer des modèles prédictifs pour anticiper les évolutions futures de la consommation d'énergie. Ces prévisions seront essentielles pour planifier des stratégies énergétiques à long terme.\n",
    "\n",
    "**Contribution à la Durabilité :** En offrant une compréhension approfondie de la consommation d'énergie, le projet aspire à contribuer activement à des initiatives de développement durable. Les insights générés pourraient inspirer des actions concrètes pour réduire l'empreinte énergétique.\n",
    "\n",
    "**Support aux Décisions Politiques et Commerciales :** Fournir des données et des analyses fiables pour éclairer les décisions politiques et commerciales en matière de gestion de l'énergie. Cela inclut la recommandation de politiques efficaces et la sensibilisation aux meilleures pratiques en matière de consommation énergétique.\n",
    "\n",
    "**Sensibilisation et Éducation :** Enfin, nous souhaitons utiliser nos résultats pour sensibiliser le public et les décideurs aux enjeux de la consommation d'énergie. L'objectif est de promouvoir une culture de consommation énergétique responsable et informée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspects techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in /opt/mamba/lib/python3.10/site-packages (4.0.1)\n",
      "Requirement already satisfied: requests in /opt/mamba/lib/python3.10/site-packages (from webdriver-manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/mamba/lib/python3.10/site-packages (from webdriver-manager) (1.0.0)\n",
      "Requirement already satisfied: packaging in /opt/mamba/lib/python3.10/site-packages (from webdriver-manager) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver-manager) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver-manager) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver-manager) (2023.11.17)\n",
      "Requirement already satisfied: BeautifulSoup4 in /opt/mamba/lib/python3.10/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/mamba/lib/python3.10/site-packages (from BeautifulSoup4) (2.5)\n",
      "Requirement already satisfied: pandas in /opt/mamba/lib/python3.10/site-packages (2.1.4)\n",
      "Requirement already satisfied: fiona in /opt/mamba/lib/python3.10/site-packages (1.9.3)\n",
      "Requirement already satisfied: shapely in /opt/mamba/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: pyproj in /opt/mamba/lib/python3.10/site-packages (3.6.1)\n",
      "Requirement already satisfied: rtree in /opt/mamba/lib/python3.10/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/mamba/lib/python3.10/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/mamba/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/mamba/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/mamba/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/mamba/lib/python3.10/site-packages (from fiona) (23.1.0)\n",
      "Requirement already satisfied: certifi in /opt/mamba/lib/python3.10/site-packages (from fiona) (2023.11.17)\n",
      "Requirement already satisfied: click~=8.0 in /opt/mamba/lib/python3.10/site-packages (from fiona) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/mamba/lib/python3.10/site-packages (from fiona) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/mamba/lib/python3.10/site-packages (from fiona) (0.7.2)\n",
      "Requirement already satisfied: munch>=2.3.2 in /opt/mamba/lib/python3.10/site-packages (from fiona) (4.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: contextily in /opt/mamba/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: geopy in /opt/mamba/lib/python3.10/site-packages (from contextily) (2.4.1)\n",
      "Requirement already satisfied: matplotlib in /opt/mamba/lib/python3.10/site-packages (from contextily) (3.8.2)\n",
      "Requirement already satisfied: mercantile in /opt/mamba/lib/python3.10/site-packages (from contextily) (1.2.1)\n",
      "Requirement already satisfied: pillow in /opt/mamba/lib/python3.10/site-packages (from contextily) (10.1.0)\n",
      "Requirement already satisfied: rasterio in /opt/mamba/lib/python3.10/site-packages (from contextily) (1.3.9)\n",
      "Requirement already satisfied: requests in /opt/mamba/lib/python3.10/site-packages (from contextily) (2.31.0)\n",
      "Requirement already satisfied: joblib in /opt/mamba/lib/python3.10/site-packages (from contextily) (1.3.2)\n",
      "Requirement already satisfied: xyzservices in /opt/mamba/lib/python3.10/site-packages (from contextily) (2023.10.1)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /opt/mamba/lib/python3.10/site-packages (from geopy->contextily) (2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->contextily) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->contextily) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->contextily) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->contextily) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->contextily) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->contextily) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->contextily) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->contextily) (2.8.2)\n",
      "Requirement already satisfied: click>=3.0 in /opt/mamba/lib/python3.10/site-packages (from mercantile->contextily) (8.1.7)\n",
      "Requirement already satisfied: affine in /opt/mamba/lib/python3.10/site-packages (from rasterio->contextily) (2.4.0)\n",
      "Requirement already satisfied: attrs in /opt/mamba/lib/python3.10/site-packages (from rasterio->contextily) (23.1.0)\n",
      "Requirement already satisfied: certifi in /opt/mamba/lib/python3.10/site-packages (from rasterio->contextily) (2023.11.17)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/mamba/lib/python3.10/site-packages (from rasterio->contextily) (0.7.2)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /opt/mamba/lib/python3.10/site-packages (from rasterio->contextily) (1.4.7)\n",
      "Requirement already satisfied: click-plugins in /opt/mamba/lib/python3.10/site-packages (from rasterio->contextily) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /opt/mamba/lib/python3.10/site-packages (from rasterio->contextily) (68.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.10/site-packages (from requests->contextily) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.10/site-packages (from requests->contextily) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.10/site-packages (from requests->contextily) (1.26.18)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->contextily) (1.16.0)\n",
      "Requirement already satisfied: geopandas in /opt/mamba/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/mamba/lib/python3.10/site-packages (from geopandas) (2.1.4)\n",
      "Requirement already satisfied: shapely>=1.7 in /opt/mamba/lib/python3.10/site-packages (from geopandas) (2.0.2)\n",
      "Requirement already satisfied: fiona>=1.8 in /opt/mamba/lib/python3.10/site-packages (from geopandas) (1.9.3)\n",
      "Requirement already satisfied: pyproj>=2.6.1.post1 in /opt/mamba/lib/python3.10/site-packages (from geopandas) (3.6.1)\n",
      "Requirement already satisfied: packaging in /opt/mamba/lib/python3.10/site-packages (from geopandas) (23.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/mamba/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (23.1.0)\n",
      "Requirement already satisfied: certifi in /opt/mamba/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (2023.11.17)\n",
      "Requirement already satisfied: click~=8.0 in /opt/mamba/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/mamba/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/mamba/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
      "Requirement already satisfied: munch>=2.3.2 in /opt/mamba/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (4.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/mamba/lib/python3.10/site-packages (from pandas>=1.0.0->geopandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/mamba/lib/python3.10/site-packages (from pandas>=1.0.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/mamba/lib/python3.10/site-packages (from pandas>=1.0.0->geopandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/mamba/lib/python3.10/site-packages (from pandas>=1.0.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->geopandas) (1.16.0)\n",
      "Requirement already satisfied: pygeos in /opt/mamba/lib/python3.10/site-packages (0.14)\n",
      "Requirement already satisfied: numpy>=1.13 in /opt/mamba/lib/python3.10/site-packages (from pygeos) (1.26.2)\n",
      "Requirement already satisfied: topojson in /opt/mamba/lib/python3.10/site-packages (1.7)\n",
      "Requirement already satisfied: numpy in /opt/mamba/lib/python3.10/site-packages (from topojson) (1.26.2)\n",
      "Requirement already satisfied: shapely in /opt/mamba/lib/python3.10/site-packages (from topojson) (2.0.2)\n",
      "Requirement already satisfied: packaging in /opt/mamba/lib/python3.10/site-packages (from topojson) (23.1)\n",
      "Requirement already satisfied: seaborn in /opt/mamba/lib/python3.10/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/mamba/lib/python3.10/site-packages (from seaborn) (1.26.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/mamba/lib/python3.10/site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in /opt/mamba/lib/python3.10/site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/mamba/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/mamba/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/mamba/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/mamba/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/mamba/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/mamba/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/mamba/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Installation des packages\n",
    "\n",
    "!pip install -q lxml\n",
    "!pip install webdriver-manager\n",
    "!pip install BeautifulSoup4\n",
    "!pip install pandas fiona shapely pyproj rtree # à faire obligatoirement en premier pour utiliser rtree ou pygeos pour les jointures spatiales\n",
    "!pip install contextily\n",
    "!pip install geopandas\n",
    "!pip install pygeos\n",
    "!pip install topojson\n",
    "!pip install seaborn\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import bs4\n",
    "import lxml\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import seaborn\n",
    "\n",
    "from urllib import request\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1 = \"https://odre.opendatasoft.com/explore/embed/dataset/conso-departement-annuelle/table/?disjunctive.libelle_departement&disjunctive.libelle_region&disjunctive.e_operateurs&disjunctive.g_operateurs&refine.annee=2021&dataChart=eyJxdWVyaWVzIjpbeyJjaGFydHMiOlt7InR5cGUiOiJjb2x1bW4iLCJmdW5jIjoiQVZHIiwieUF4aXMiOiJjb25zb3RvdGFsZSIsInNjaWVudGlmaWNEaXNwbGF5Ijp0cnVlLCJjb2xvciI6IiM2NmMyYTUifV0sInhBeGlzIjoibGliZWxsZV9kZXBhcnRlbWVudCIsIm1heHBvaW50cyI6NTAsInNvcnQiOiIiLCJjb25maWciOnsiZGF0YXNldCI6ImNvbnNvLWRlcGFydGVtZW50LWFubnVlbGxlIiwib3B0aW9ucyI6eyJkaXNqdW5jdGl2ZS5saWJlbGxlX2RlcGFydGVtZW50Ijp0cnVlLCJkaXNqdW5jdGl2ZS5saWJlbGxlX3JlZ2lvbiI6dHJ1ZSwiZGlzanVuY3RpdmUuZV9vcGVyYXRldXJzIjp0cnVlLCJkaXNqdW5jdGl2ZS5nX29wZXJhdGV1cnMiOnRydWUsInJlZmluZS5hbm5lZSI6IjIwMjEifX19XSwidGltZXNjYWxlIjoiIiwiZGlzcGxheUxlZ2VuZCI6dHJ1ZSwiYWxpZ25Nb250aCI6dHJ1ZX0%3D&location=3,17.56025,53.4375&basemap=jawg.light\"\n",
    "url_2 = \"https://www.insee.fr/fr/statistiques/6436484?sommaire=6036904#tableau-figure1_radio1\"\n",
    "url_3 = \"https://odre.opendatasoft.com/explore/dataset/temperature-quotidienne-departementale/information/?disjunctive.departement\"\n",
    "url_4 = \"https://www.insee.fr/fr/statistiques/6436484?sommaire=6036904#tableau-figure1_radio1\"\n",
    "url_5 = \"https://www.observatoire-des-territoires.gouv.fr/outils/cartographie-interactive/#bbox=-1052198,6661338,2597056,1619174&c=indicator&i=insee_rp_hist_1968.part_logt_vacant&s=2020&view=map9\"\n",
    "url_6 = \"https://ufe-electricite.fr/watt-the-carte/deploiement-bornes-de-recharge-en-france/dans-les-territoires/\"\n",
    "url_7 = \"https://www.carburants.org/borne-electrique/departements/\"\n",
    "url_8 : \"https://www.observatoire-des-territoires.gouv.fr/nombre-dentreprises-par-secteurs-dactivite\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Collecte et Exploration des Données (Communes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources de Données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bases de données pre-existantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Consommation totale d'énergie par commune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'conso_energie.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m table_conso_com \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconso_energie.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m table_conso_com\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Affichage de la table\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'conso_energie.csv'"
     ]
    }
   ],
   "source": [
    "table_conso_com = pd.read_csv('conso_energie.csv',sep=';')\n",
    "table_conso_com.head()\n",
    "\n",
    "# Affichage de la table\n",
    "table_conso_com.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logements vacants par commune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = https://www.data.gouv.fr/fr/datasets/niveau-de-vie-des-francais-par-commune/\n",
    "table_logements_vacants_com = pd.read_csv('logement_vacants_com.csv', sep=';', encoding='ISO-8859-1')\n",
    "table_logements_vacants_com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nombre d'entreprises par commune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = https://www.observatoire-des-territoires.gouv.fr/outils/cartographie-interactive/#c=indicator&f=TOT&i=demo_ent_sect.ent_tot&s=2021&view=map59\n",
    "table_nb_entr_com = pd.read_csv('table_nb_entr_com.csv',sep=';')\n",
    "table_nb_entr_com.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Niveau de vie par commune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = https://www.data.gouv.fr/fr/datasets/niveau-de-vie-des-francais-par-commune/\n",
    "table_niveau_vie_com = pd.read_csv('niveau_vie_com.csv',sep=';')\n",
    "table_niveau_vie_com.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bases de données webscrappées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Population par commune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url_communes = \"https://fr.wikipedia.org/wiki/Listes_des_communes_de_France\"\n",
    "text_communes = request.urlopen(url_communes).read().decode('utf-8')\n",
    "page_communes = BeautifulSoup(text_communes, 'html.parser')\n",
    "tableau_communes = page_communes.find('table', {'class': 'wikitable'})\n",
    "tableau_communes = tableau_communes.find('tbody')\n",
    "lignes_communes = tableau_communes.find_all('tr')\n",
    "lignes_communes = lignes_communes[:-13]\n",
    "\n",
    "# Liste pour stocker les contenus après \"a href\"\n",
    "liste_url_communes = []\n",
    "\n",
    "# Parcourir chaque ligne dans lignes_communes\n",
    "for ligne in lignes_communes:\n",
    "    # Trouver toutes les balises <td> dans la ligne\n",
    "    td_tags = ligne.find_all('td')\n",
    "\n",
    "    if len(td_tags) >= 3:\n",
    "        if td_tags[-3].text.strip() != '75':\n",
    "            derniere_td = td_tags[-1]\n",
    "            a_tag = derniere_td.find('a')\n",
    "            if a_tag:\n",
    "                contenu_apres_href = a_tag.get('href')\n",
    "                liste_url_communes.append(contenu_apres_href)\n",
    "\n",
    "dico_communes = {}\n",
    "liste_code_communes = []\n",
    "\n",
    "for url in liste_url_communes:\n",
    "    text = request.urlopen(\"https://fr.wikipedia.org\" + url).read().decode('utf-8')\n",
    "    page = BeautifulSoup(text, 'html.parser')  # Utilisez html.parser au lieu de lxml\n",
    "    tableau = page.find('table', {'class': 'wikitable sortable titre-en-couleur'})\n",
    "    tableau = tableau.find('tbody')\n",
    "    lignes = tableau.find_all('tr')\n",
    "    lignes.pop(0)\n",
    "    lignes.pop(-1)\n",
    "\n",
    "    for ligne in lignes:\n",
    "        donnees = ligne.find_all('td')\n",
    "        code_insee = donnees[1].text.strip()\n",
    "        liste_code_communes.append(code_insee)\n",
    "        pop_commune = donnees[-3].text.strip()\n",
    "        dico_communes[code_insee] = pop_commune\n",
    "\n",
    "table_pop_com = pd.DataFrame.from_dict(dico_communes,orient='index').reset_index()\n",
    "table_pop_com = table_pop_com.rename(columns={'index':'Code commune'}) \n",
    "table_pop_com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Température par commune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire pour stocker les moyennes de température par commune\n",
    "#dico_temp_communes = {}\n",
    "\n",
    "#root_api = \"https://public.opendatasoft.com\"\n",
    "\n",
    "# Boucle sur chaque codegeo\n",
    "#for codegeo in liste_code_communes:\n",
    "    # Construire l'URL avec le codegeo actuel\n",
    "    #url = f\"{root_api}/api/explore/v2.1/catalog/datasets/donnees-synop-essentielles-omm/records?select=codegeo%2C%20tc%2C%20latitude%2C%20longitude&where=codegeo%3D%22{codegeo}%22&limit=99\"\n",
    "\n",
    "    # Récupérer les données depuis l'API\n",
    "    #req = requests.get(url)\n",
    "    #temp = req.json()\n",
    "    #results = temp.get('results', [])\n",
    "    \n",
    "    # Créer un DataFrame avec les résultats\n",
    "    #df = pd.DataFrame(results)\n",
    "    \n",
    "    # Vérifier si la colonne 'tc' existe dans le DataFrame\n",
    "    #if 'tc' in df.columns:\n",
    "        # Calculer la moyenne de la colonne 'tc'\n",
    "        #moyenne = round(df['tc'].mean(), 2)\n",
    "        \n",
    "        # Ajouter la moyenne au dictionnaire avec le codegeo comme clé\n",
    "        #dico_temp_communes[codegeo] = moyenne\n",
    "    # else:\n",
    "        # print(f\"La colonne 'tc' est absente pour le codegeo {codegeo}\")\n",
    "\n",
    "# Afficher le dictionnaire final\n",
    "# print(dico_temp_communes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requests\n",
    "#import pandas as pd\n",
    "#from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Initialisation d'une session de requêtes\n",
    "#session = requests.Session()\n",
    "\n",
    "#def fetch_data(codegeo):\n",
    "    #url = f\"{root_api}/api/explore/v2.1/catalog/datasets/donnees-synop-essentielles-omm/records?select=codegeo%2C%20tc%2C%20latitude%2C%20longitude&where=codegeo%3D%22{codegeo}%22&limit=99\"\n",
    "    #try:\n",
    "        #response = session.get(url)\n",
    "        #response.raise_for_status()\n",
    "        #data = response.json()\n",
    "        #return data.get('results', [])\n",
    "    #except requests.RequestException as e:\n",
    "        #print(f\"Erreur lors de la récupération des données pour {codegeo}: {e}\")\n",
    "        #return []\n",
    "\n",
    "# Traitement des données en parallèle\n",
    "#with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    #results = executor.map(fetch_data, liste_code_communes)\n",
    "\n",
    "# Traitement des résultats\n",
    "#all_data = []\n",
    "#for result in results:\n",
    "    #all_data.extend(result)\n",
    "\n",
    "# Création d'un DataFrame unique\n",
    "#df = pd.DataFrame(all_data)\n",
    "\n",
    "# Calcul des moyennes\n",
    "#if 'tc' in df.columns:\n",
    "    #dico_temp_communes = df.groupby('codegeo')['tc'].mean().round(2).to_dict()\n",
    "\n",
    "# Afficher le dictionnaire final\n",
    "# print(dico_temp_communes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On se rend compte qu'on a plein de données manquantes. Pour lutter contre ce problème on associe à chaque commune la température du département, en faisant l'hypothèse que la température est assez homogène dans un département."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de base et structure de l'URL de l'API\n",
    "root_api = \"https://odre.opendatasoft.com\"\n",
    "base_url = \"/api/explore/v2.1/catalog/datasets/temperature-quotidienne-departementale/records\"\n",
    "base_query = \"?select=date_obs%2Ccode_insee_departement%2Cdepartement%2Ctmoy&order_by=code_insee_departement&limit=99&refine=date_obs%3A%222021%22\"\n",
    "\n",
    "# Collecte des données pour chaque mois\n",
    "df_list = []\n",
    "for i in range(1, 13):\n",
    "    date_str = f\"2021-{i:02d}-01\"\n",
    "    url_api = f\"{root_api}{base_url}{base_query}&where=date_obs%3Ddate'{date_str}'\"\n",
    "    req = requests.get(url_api)\n",
    "    temp = req.json()\n",
    "    results = temp.get('results', [])\n",
    "    df = pd.DataFrame(results)\n",
    "    if not df.empty:\n",
    "        df = df[['date_obs', 'code_insee_departement', 'departement','tmoy']]\n",
    "        df_list.append(df)\n",
    "\n",
    "# Fusionner tous les DataFrames en un seul\n",
    "df_final = pd.concat(df_list)\n",
    "\n",
    "# Calcul de la moyenne des températures par code et nom de département\n",
    "table_temperatures = df_final.groupby(['code_insee_departement', 'departement'])['tmoy'].mean().reset_index()\n",
    "\n",
    "# Affichage du DataFrame final\n",
    "table_temperatures.head()\n",
    "\n",
    "# Création d'un DataFrame à partir de la liste des codes INSEE\n",
    "data_communes = {'code_commune': liste_code_communes}\n",
    "df_communes = pd.DataFrame(data_communes)\n",
    "\n",
    "# Exécution d'une jointure entre les deux DataFrames\n",
    "table_temperatures_com = pd.merge(df_communes, table_temperatures, left_on=df_communes['code_commune'].str[:2], right_on=table_temperatures['code_insee_departement'])\n",
    "\n",
    "# Afficher le résultat\n",
    "table_temperatures_com[['code_commune', 'tmoy']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusion des bases de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualisation des dataframe a fusionner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes nécessaires\n",
    "df_filtered = table_conso_com[['annee','code_commune', 'libelle_commune', 'consototale']]\n",
    "\n",
    "# Trier les données par commune et année, en ordre décroissant\n",
    "df_filtered = df_filtered.sort_values(by=['code_commune', 'annee'], ascending=[True, False])\n",
    "\n",
    "# Garder la première occurrence pour chaque commune\n",
    "df_filtered = df_filtered.drop_duplicates(subset='code_commune')\n",
    "\n",
    "# Réinitialiser l'index\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "\n",
    "# Afficher le DataFrame final\n",
    "df_filtered.head()\n",
    "\n",
    "table_conso_com=df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_temperatures_com.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_logements_vacants_com=table_logements_vacants_com.rename(columns={\n",
    "    'codgeo': 'code_commune',\n",
    "    'libgeo': 'libelle_commune',\n",
    "    'an': 'an',\n",
    "    'part_logt_vacant': 'logements_vacants_%'\n",
    "})\n",
    "table_logements_vacants_com.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_pop_com=table_pop_com.rename(columns={\n",
    "    'Code commune': 'code_commune',\n",
    "    0: 'population',\n",
    "})\n",
    "table_pop_com['population'] = table_pop_com['population'].str.replace(r'\\s*\\(2020\\)', '', regex=True)\n",
    "table_pop_com.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_niveau_vie_com=table_niveau_vie_com.rename(columns={\n",
    "    'CODGEO': 'code_commune',\n",
    "    'LIBGEO': 'libelle_commune',\n",
    "    'MED14': 'niveau_de_vie'\n",
    "})\n",
    "table_niveau_vie_com.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_nb_entr_com = table_nb_entr_com.rename(columns={\n",
    "    'Code': 'code_commune',\n",
    "    'Libellé': 'libelle_commune',\n",
    "    'Nombre d\\'entreprises par secteurs d\\'activité 2021': 'nombre_entreprises',\n",
    "    'Nombre d\\'entreprises par secteurs d\\'activité 2021.1': 'pas_compris_cette_colonne'\n",
    "})\n",
    "table_nb_entr_com.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Traitement des tableaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_conso_communes=table_conso_com[['code_commune','libelle_commune','consototale']]\n",
    "table_logements_vacants_communes = table_logements_vacants_com.loc[table_logements_vacants_com.groupby('code_commune')['an'].idxmax()]\n",
    "table_nb_entr_communes=table_nb_entr_com[['code_commune','libelle_commune','nombre_entreprises']]\n",
    "table_niveau_vie_communes=table_niveau_vie_com[['code_commune','libelle_commune','niveau_de_vie']]\n",
    "table_pop_communes=table_pop_com[['code_commune','population']]\n",
    "table_temperatures_communes=table_temperatures_com[['code_commune','tmoy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fusion deux par deux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion des DataFrames\n",
    "df_merged = table_conso_communes.merge(table_logements_vacants_communes, on='code_commune', how='inner')\n",
    "df_merged = df_merged.merge(table_nb_entr_communes, on='code_commune', how='inner', suffixes=('', '_entr'))\n",
    "df_merged = df_merged.merge(table_niveau_vie_communes, on='code_commune', how='inner', suffixes=('', '_nv'))\n",
    "df_merged = df_merged.merge(table_pop_communes, on='code_commune', how='inner')\n",
    "df_merged = df_merged.merge(table_temperatures_communes, on='code_commune', how='inner')\n",
    "\n",
    "# Nettoyage des colonnes\n",
    "table_donnees = df_merged[['code_commune', 'libelle_commune', 'consototale', 'logements_vacants_%', 'nombre_entreprises', 'niveau_de_vie', 'population', 'tmoy']]\n",
    "\n",
    "table_donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_donnees = table_donnees.dropna()\n",
    "table_donnees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration Initiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apercu des donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des premières lignes\n",
    "table_donnees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des informations sur les types de données et les valeurs manquantes\n",
    "table_donnees.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Nettoyage et Préparation des Données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des colonnes en chaînes de caractères et remplacement des virgules et espaces insécables\n",
    "table_donnees['logements_vacants_%'] = table_donnees['logements_vacants_%'].astype(str).str.replace(',', '.').astype(float)\n",
    "table_donnees['nombre_entreprises'] = table_donnees['nombre_entreprises'].astype(str).str.replace(',', '.').astype(float)\n",
    "table_donnees['niveau_de_vie'] = table_donnees['niveau_de_vie'].astype(str).str.replace(',', '.').astype(float)\n",
    "table_donnees['population'] = table_donnees['population'].astype(str).str.replace('\\xa0', '').replace(' ', '').astype(int)\n",
    "\n",
    "# Vérification des conversions\n",
    "print(table_donnees.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatage et Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Analyse Exploratoire des Données (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistiques Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives pour les colonnes numériques\n",
    "stats_descriptives = table_donnees.describe()\n",
    "\n",
    "# Mode pour les colonnes catégorielles et numériques\n",
    "mode = table_donnees.mode().iloc[0]\n",
    "\n",
    "# Corrélations entre les variables numériques\n",
    "# Assurez-vous que toutes les colonnes incluses sont de type numérique\n",
    "correlations = table_donnees.select_dtypes(include=[float, int]).corr()\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"\\nStatistiques descriptives :\\n\", stats_descriptives)\n",
    "print(\"\\nMode :\\n\", mode)\n",
    "print(\"\\nCorrélations :\\n\", correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Configuration du style des graphiques\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Histogrammes améliorés pour les variables numériques\n",
    "for col in ['consototale', 'logements_vacants_%', 'nombre_entreprises', 'niveau_de_vie', 'population', 'tmoy']:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(table_donnees[col], kde=True, color=\"skyblue\", edgecolor='black', bins=30)\n",
    "    plt.title(f'Distribution de {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Fréquence')\n",
    "    plt.show()\n",
    "\n",
    "# Boxplots améliorés pour les variables numériques\n",
    "for col in ['consototale', 'logements_vacants_%', 'nombre_entreprises', 'niveau_de_vie', 'population', 'tmoy']:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=table_donnees[col], palette=\"Set2\")\n",
    "    plt.title(f'Boxplot de {col}')\n",
    "    plt.show()\n",
    "\n",
    "# Scatter plots améliorés pour les relations entre deux variables numériques\n",
    "# Exemple : 'population' vs 'consototale'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='population', y='consototale', data=table_donnees, scatter_kws={'alpha':0.5}, line_kws={'color':'red'})\n",
    "plt.title('Relation entre Population et Consommation Totale')\n",
    "plt.xlabel('Population')\n",
    "plt.ylabel('Consommation Totale')\n",
    "plt.show()\n",
    "\n",
    "# Heatmap améliorée pour la matrice de corrélation\n",
    "# Sélectionnez uniquement les colonnes numériques pour la corrélation\n",
    "data_numerique = table_donnees.select_dtypes(include=[np.number])\n",
    "# Calcul de la matrice de corrélation sur les données numériques\n",
    "corr = data_numerique.corr()\n",
    "# Création de la heatmap\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', mask=mask)\n",
    "plt.title('Matrice de corrélation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Analyse et Visualisation par Secteur et par Département"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphique de statitistiques descriptives\n",
    "\n",
    "# Import seaborn\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# Apply the default theme\n",
    "graph= sns.relplot(data= table_donnees, x=\"niveau_de_vie\", y=\"consototale\",height=6,aspect=3)\n",
    "\n",
    "# Définissez les marques de l'axe des abscisses à intervalles de 1000\n",
    "xticks_interval = np.arange(13000, 31000, 1000)\n",
    "graph.ax.set_xticks(xticks_interval)\n",
    "\n",
    "# Affichez le graphique\n",
    "plt.show()\n",
    "\n",
    "# Affichez le graphique\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Max min\n",
    "#Mt=table_donnees['tmoy'].max()\n",
    "#mt=table_donnees['tmoy'].min()\n",
    "#on distingue trois groupe de dépapartement selon la température pour observer les causalités et les correlations.\n",
    "#table_donnees['grp_tmp']=[ \"Chaud\" if t > 2*(Mt-mt)/3 +mt  else (\"Froid\" if t < (Mt-mt)/3 +mt else \"Doux\") for t in table_donnees['tmoy']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=table_donnees, y=\"consototale\", x=\"tmoy\", height=6, aspect=2)\n",
    "#hue=\"grp_tmp\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=table_donnees)\n",
    "#, hue=\"grp_tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carte de france avec les départements: conversion des donées pour une analyse en Geopadans\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Conversion des données \"geom\" qui sont en GEOJSON en données \"géometry\" que Geopanda peut traiter\n",
    "#table_donnees['geometry'] = table_donnees['geom'].apply(lambda x: shape(x['geometry']))\n",
    "#gdf = gpd.GeoDataFrame(table_donnees, geometry='geometry')\n",
    "\n",
    "# Créez une figure et des axes\n",
    "#fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Affichez la carte à partir du GeoDataFrame\n",
    "#gdf.plot(ax=ax, color='green', edgecolor='black')\n",
    "\n",
    "# Supprimez les axes\n",
    "#ax.set_axis_off()\n",
    "\n",
    "# Supprimez les valeurs des axes x et y\n",
    "#ax.set_xticks([])\n",
    "#ax.set_yticks([])\n",
    "\n",
    "# Ajoutez un titre à la carte\n",
    "#plt.title(\"Départements\")\n",
    "\n",
    "# Affichez la carte\n",
    "#plt.show()\n",
    "\n",
    "#Il manque une dizaines de départements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation de la temperature par département\n",
    "\n",
    "#from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# Créez une figure et des axes\n",
    "#fig, ax = plt.subplots(figsize=(12, 12))\n",
    "# Tracé de la carte avec la couleur basée sur les températures \n",
    "#gdf.plot(column='temperature', cmap='coolwarm', linewidth=0.8, ax=ax, edgecolor='0.8')\n",
    "# Ajout d'une barre de couleur :\n",
    "#divider = make_axes_locatable(ax)\n",
    "#cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "#sm = plt.cm.ScalarMappable(cmap='coolwarm', norm=plt.Normalize(vmin=gdf['temperature'].min(), vmax=gdf['temperature'].max()))\n",
    "#sm._A = []\n",
    "#cbar = plt.colorbar(sm, cax=cax)\n",
    "\n",
    "# Suppression des axes\n",
    "#ax.set_axis_off()\n",
    "\n",
    "# Ajouter un titre à la carte\n",
    "#plt.suptitle(\"Carte de France - Températures des départements\", fontsize=15, x=0.5, y=0.80)\n",
    "\n",
    "# Afficher la carte\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation de la consommation d'électricté par département\n",
    "\n",
    "#from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib.colors import Normalize\n",
    "#from matplotlib.cm import ScalarMappable\n",
    "# Créez une figure et des axes\n",
    "#fig, ax = plt.subplots(figsize=(12, 12))\n",
    "# Ecart par rapport à la moyenne de consomation\n",
    "#gdf['diff_moyenne'] = (gdf['consommation'] - gdf['consommation'].mean())\n",
    "# Tracé de la carte avec la couleur basée sur les températures \n",
    "#gdf.plot(column='diff_moyenne', cmap='RdYlGn_r', linewidth=0.8, ax=ax, edgecolor='0.8')\n",
    "# Ajout d'une barre de couleur :\n",
    "#divider = make_axes_locatable(ax)\n",
    "#cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "#sm = plt.cm.ScalarMappable(cmap='RdYlGn_r', norm=plt.Normalize(vmax=gdf['diff_moyenne'].max(), vmin=gdf['diff_moyenne'].min()))\n",
    "#sm._A = []\n",
    "#cbar = plt.colorbar(sm, cax=cax)\n",
    "\n",
    "# Suppression des axes\n",
    "#ax.set_axis_off()\n",
    "\n",
    "# Ajouter un titre à la carte\n",
    "#plt.suptitle(\"Carte de France - Consommation électricité des départements\", fontsize=15, x=0.5, y=0.80)\n",
    "\n",
    "# Afficher la carte\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import folium\n",
    "#import pandas as pd\n",
    "#m = folium.Map(location=[46.6031, 1.8883], zoom_start=6)\n",
    "#for index, row in table_donnees.iterrows():\n",
    "#    folium.GeoJson(row['geom'], name=row['nom_departement']).add_to(m)\n",
    "#m.save('carte.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison par Secteur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Géographique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Modélisation et Prédictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix des Modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement et Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement de nombreux modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_donnees_pred=table_donnees.drop(['code_commune', 'libelle_commune'],axis=1)\n",
    "\n",
    "# Séparation des variables indépendantes et dépendantes\n",
    "y = table_donnees_pred['consototale']\n",
    "X = table_donnees_pred.drop(['consototale'], axis=1)\n",
    "\n",
    "# Séparation en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dictionnaire pour stocker les erreurs des modèles\n",
    "model_errors = {}\n",
    "\n",
    "# Modèles à tester\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"Support Vector Regression\": SVR(),\n",
    "    \"Neural Network\": MLPRegressor(max_iter=1000)  # Augmentation du nombre d'itérations pour une meilleure convergence\n",
    "}\n",
    "\n",
    "# Entraînement et évaluation de chaque modèle\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    model_errors[name] = mse\n",
    "    print(f\"{name}: MSE = {mse}\")\n",
    "\n",
    "# Trouver le modèle avec l'erreur la plus faible\n",
    "best_model = min(model_errors, key=model_errors.get)\n",
    "print(f\"\\nMeilleur modèle: {best_model} avec une MSE de {model_errors[best_model]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible problème, à discuter et corriger.\n",
    "- Échelle des données ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régressions linéaires pour l'interprétabilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Méthode exhaustive de sélection de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation des données pour différentes combinaisons\n",
    "def transform_data(df, transformation):\n",
    "    transformed_df = df.copy()\n",
    "    for col in df.columns:\n",
    "        # Vérifier si la colonne est numérique avant d'appliquer une transformation\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            if transformation == \"log\" and df[col].min() > 0:\n",
    "                transformed_df[col] = np.log(df[col])\n",
    "            elif transformation == \"squared\":\n",
    "                transformed_df[col] = np.square(df[col])\n",
    "    return transformed_df\n",
    "\n",
    "\n",
    "# Sélection exhaustive des variables pour la régression linéaire\n",
    "def best_feature_combination(table_donnees, target_column):\n",
    "    best_aic = float('inf')\n",
    "    best_bic = float('inf')\n",
    "    best_combination = None\n",
    "    best_transformation = None\n",
    "    features = [col for col in table_donnees.columns if col != target_column]\n",
    "\n",
    "    for transformation in [\"log\", \"squared\", \"none\"]:\n",
    "        transformed_table = transform_data(table_donnees, transformation) if transformation != \"none\" else table_donnees\n",
    "\n",
    "        for L in range(1, len(features) + 1):\n",
    "            for subset in combinations(features, L):\n",
    "                X = transformed_table[list(subset)]\n",
    "                y = transformed_table[target_column]\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "                model = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n",
    "                aic = model.aic\n",
    "                bic = model.bic\n",
    "\n",
    "                if aic < best_aic and bic < best_bic:\n",
    "                    best_aic = aic\n",
    "                    best_bic = bic\n",
    "                    best_combination = subset\n",
    "                    best_transformation = transformation\n",
    "\n",
    "    return best_combination, best_transformation, best_aic, best_bic\n",
    "\n",
    "best_features, best_transformation, best_aic, best_bic = best_feature_combination(table_donnees_pred, 'consototale')\n",
    "\n",
    "# Affichage des meilleurs résultats\n",
    "print(f\"Meilleures caractéristiques: {best_features}\")\n",
    "print(f\"Meilleure transformation: {best_transformation}\")\n",
    "print(f\"Meilleur AIC: {best_aic}\")\n",
    "print(f\"Meilleur BIC: {best_bic}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stats descriptives des variables identifiées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration des graphiques\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Histogrammes\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i, col in enumerate(['nombre_entreprises', 'niveau_de_vie', 'population']):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    sns.histplot(table_donnees_pred[col], kde=True)\n",
    "    plt.title(f'Histogramme de {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Diagrammes de dispersion\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i, col in enumerate(['nombre_entreprises', 'niveau_de_vie', 'population']):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    sns.scatterplot(data=table_donnees_pred, x=col, y='consototale')\n",
    "    plt.title(f'{col} vs consototale')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Heatmap de corrélation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(table_donnees_pred.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Matrice de corrélation')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Entrainement du modèle sélectionné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display, Latex, HTML\n",
    "\n",
    "\n",
    "# Ignorer les avertissements pour une sortie propre\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Fonction pour transformer les données\n",
    "def transform_data(df, transformation):\n",
    "    transformed_df = df.copy()\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            if transformation == \"log\" and df[col].min() > 0:\n",
    "                transformed_df[col] = np.log(df[col])\n",
    "            elif transformation == \"squared\":\n",
    "                transformed_df[col] = np.square(df[col])\n",
    "    return transformed_df\n",
    "\n",
    "# Transformation des données\n",
    "transformed_data = transform_data(table_donnees_pred, 'log')\n",
    "\n",
    "# Sélectionner les meilleures caractéristiques pour le modèle\n",
    "X = transformed_data[['nombre_entreprises', 'niveau_de_vie', 'population']]\n",
    "y = transformed_data['consototale']\n",
    "\n",
    "# Entraînement du modèle de régression linéaire\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n",
    "\n",
    "# Récupération des coefficients\n",
    "coefficients = model.params\n",
    "intercept = coefficients[0]\n",
    "coef = coefficients[1:]\n",
    "\n",
    "# Formatage de l'équation de régression pour l'affichage en LaTeX\n",
    "model_eq = r\"$$\\text{consototale} = \"\n",
    "model_eq += f\"{intercept:.2f} \"\n",
    "for var, beta in zip(['nombre_entreprises', 'niveau_de_vie', 'population'], coef):\n",
    "    sign = '+' if beta >= 0 else ''\n",
    "    model_eq += f\" {sign} {beta:.2f} \\log({var}) \"\n",
    "model_eq += r\"$$\"\n",
    "\n",
    "print(\"Modèle de régression linéaire :\")\n",
    "display(Latex(model_eq))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Préparation des données avec la meilleure combinaison et transformation\n",
    "transformed_table = transform_data(table_donnees, best_transformation)\n",
    "X = transformed_table[list(best_features)]\n",
    "y = transformed_table['consototale']\n",
    "\n",
    "# Séparation en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement du modèle\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n",
    "\n",
    "# Affichage des résultats du modèle\n",
    "print(model.summary())\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = model.predict(sm.add_constant(X_test))\n",
    "\n",
    "# Visualisation des résidus\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.residplot(x=y_pred, y=residuals, lowess=True, line_kws={'color': 'red', 'lw': 1})\n",
    "plt.title('Résidus vs Valeurs Prédites')\n",
    "plt.xlabel('Valeurs Prédites')\n",
    "plt.ylabel('Résidus')\n",
    "plt.show()\n",
    "\n",
    "# Diagramme de dispersion pour montrer les prédictions par rapport aux valeurs réelles\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)  # ligne de référence\n",
    "plt.title('Valeurs Réelles vs Prédites')\n",
    "plt.xlabel('Valeurs Réelles')\n",
    "plt.ylabel('Valeurs Prédites')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Une petite application de prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLICATION TEXTUELLE\n",
    "\n",
    "def predict_consototale(population, niveau_de_vie, nombre_entreprises, model):\n",
    "    # Transformation des entrées\n",
    "    log_population = np.log(population)\n",
    "    log_niveau_de_vie = np.log(niveau_de_vie)\n",
    "    log_nombre_entreprises = np.log(nombre_entreprises)\n",
    "    \n",
    "    # Préparation des données pour la prédiction\n",
    "    X_pred = np.array([[1, log_nombre_entreprises, log_niveau_de_vie, log_population]])  # Ajoutez '1' pour la constante\n",
    "    \n",
    "    # Prédiction en utilisant le modèle\n",
    "    prediction = model.predict(X_pred)[0]\n",
    "    return prediction\n",
    "\n",
    "# Assurez-vous que 'model' est votre modèle entraîné\n",
    "# model = ...\n",
    "\n",
    "# Demande de saisie des valeurs à l'utilisateur\n",
    "population = float(input(\"Entrez la population: \"))\n",
    "niveau_de_vie = float(input(\"Entrez le niveau de vie: \"))\n",
    "nombre_entreprises = float(input(\"Entrez le nombre d'entreprises: \"))\n",
    "\n",
    "# Prédiction de la consototale\n",
    "consototale_estimee = predict_consototale(population, niveau_de_vie, nombre_entreprises, model)\n",
    "\n",
    "print(f\"La consototale estimée est : {consototale_estimee:.1f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLICATION WIDGET\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def predict_consototale(population, niveau_de_vie, nombre_entreprises, model):\n",
    "    log_population = np.log(population)\n",
    "    log_niveau_de_vie = np.log(niveau_de_vie)\n",
    "    log_nombre_entreprises = np.log(nombre_entreprises)\n",
    "    X_pred = np.array([[1, log_nombre_entreprises, log_niveau_de_vie, log_population]])\n",
    "    prediction = model.predict(X_pred)[0]\n",
    "    return prediction\n",
    "\n",
    "def on_predict(b):\n",
    "    try:\n",
    "        population = float(population_input.value)\n",
    "        niveau_de_vie = float(niveau_de_vie_input.value)\n",
    "        nombre_entreprises = float(nombre_entreprises_input.value)\n",
    "        consototale_estimee = predict_consototale(population, niveau_de_vie, nombre_entreprises, model)\n",
    "        output.clear_output()\n",
    "        with output:\n",
    "            print(f\"La consototale estimée est : {consototale_estimee}\")\n",
    "    except ValueError as e:\n",
    "        output.clear_output()\n",
    "        with output:\n",
    "            print(\"Erreur : Veuillez entrer des valeurs numériques valides.\")\n",
    "\n",
    "population_input = widgets.FloatText(value=0, description='Population:')\n",
    "niveau_de_vie_input = widgets.FloatText(value=0, description='Niv de vie:')\n",
    "nombre_entreprises_input = widgets.FloatText(value=0, description='Nb Etp:')\n",
    "\n",
    "predict_button = widgets.Button(description=\"Prédire\")\n",
    "predict_button.on_click(on_predict)\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "display(population_input, niveau_de_vie_input, nombre_entreprises_input, predict_button, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Évaluation des Résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interprétation des Modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesures de Performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Synthèse et Recommandations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions Clés "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommandations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
