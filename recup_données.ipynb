{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "edd1bd22-2369-4e81-b6b8-ede4e73d9bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1 = \"https://odre.opendatasoft.com/explore/embed/dataset/conso-departement-annuelle/table/?disjunctive.libelle_departement&disjunctive.libelle_region&disjunctive.e_operateurs&disjunctive.g_operateurs&refine.annee=2021&dataChart=eyJxdWVyaWVzIjpbeyJjaGFydHMiOlt7InR5cGUiOiJjb2x1bW4iLCJmdW5jIjoiQVZHIiwieUF4aXMiOiJjb25zb3RvdGFsZSIsInNjaWVudGlmaWNEaXNwbGF5Ijp0cnVlLCJjb2xvciI6IiM2NmMyYTUifV0sInhBeGlzIjoibGliZWxsZV9kZXBhcnRlbWVudCIsIm1heHBvaW50cyI6NTAsInNvcnQiOiIiLCJjb25maWciOnsiZGF0YXNldCI6ImNvbnNvLWRlcGFydGVtZW50LWFubnVlbGxlIiwib3B0aW9ucyI6eyJkaXNqdW5jdGl2ZS5saWJlbGxlX2RlcGFydGVtZW50Ijp0cnVlLCJkaXNqdW5jdGl2ZS5saWJlbGxlX3JlZ2lvbiI6dHJ1ZSwiZGlzanVuY3RpdmUuZV9vcGVyYXRldXJzIjp0cnVlLCJkaXNqdW5jdGl2ZS5nX29wZXJhdGV1cnMiOnRydWUsInJlZmluZS5hbm5lZSI6IjIwMjEifX19XSwidGltZXNjYWxlIjoiIiwiZGlzcGxheUxlZ2VuZCI6dHJ1ZSwiYWxpZ25Nb250aCI6dHJ1ZX0%3D&location=3,17.56025,53.4375&basemap=jawg.light\"\n",
    "url_2 = \"https://www.insee.fr/fr/statistiques/6436484?sommaire=6036904#tableau-figure1_radio1\"\n",
    "url_3 = \"https://odre.opendatasoft.com/explore/dataset/temperature-quotidienne-departementale/information/?disjunctive.departement\"\n",
    "url_4 = \"https://www.insee.fr/fr/statistiques/6436484?sommaire=6036904#tableau-figure1_radio1\"\n",
    "url_5 = \"https://www.observatoire-des-territoires.gouv.fr/outils/cartographie-interactive/#c=indicator&i=insee_rp_hist_1968.part_logt_vacant&s=2020&view=map9\"\n",
    "url_6 = \"https://ufe-electricite.fr/watt-the-carte/deploiement-bornes-de-recharge-en-france/dans-les-territoires/\"\n",
    "url_7 = \"https://www.carburants.org/borne-electrique/departements/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a72c2552-19d8-4955-8778-fbb1722bfe63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in /opt/mamba/lib/python3.10/site-packages (4.0.1)\n",
      "Requirement already satisfied: requests in /opt/mamba/lib/python3.10/site-packages (from webdriver-manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/mamba/lib/python3.10/site-packages (from webdriver-manager) (1.0.0)\n",
      "Requirement already satisfied: packaging in /opt/mamba/lib/python3.10/site-packages (from webdriver-manager) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver-manager) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver-manager) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver-manager) (2023.11.17)\n",
      "Requirement already satisfied: BeautifulSoup4 in /opt/mamba/lib/python3.10/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/mamba/lib/python3.10/site-packages (from BeautifulSoup4) (2.5)\n",
      "Requirement already satisfied: pandas in /opt/mamba/lib/python3.10/site-packages (2.1.3)\n",
      "Requirement already satisfied: fiona in /opt/mamba/lib/python3.10/site-packages (1.9.3)\n",
      "Requirement already satisfied: shapely in /opt/mamba/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: pyproj in /opt/mamba/lib/python3.10/site-packages (3.6.1)\n",
      "Requirement already satisfied: rtree in /opt/mamba/lib/python3.10/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/mamba/lib/python3.10/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/mamba/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/mamba/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/mamba/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/mamba/lib/python3.10/site-packages (from fiona) (23.1.0)\n",
      "Requirement already satisfied: certifi in /opt/mamba/lib/python3.10/site-packages (from fiona) (2023.11.17)\n",
      "Requirement already satisfied: click~=8.0 in /opt/mamba/lib/python3.10/site-packages (from fiona) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/mamba/lib/python3.10/site-packages (from fiona) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/mamba/lib/python3.10/site-packages (from fiona) (0.7.2)\n",
      "Requirement already satisfied: munch>=2.3.2 in /opt/mamba/lib/python3.10/site-packages (from fiona) (4.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting contextily\n",
      "  Downloading contextily-1.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting geopy (from contextily)\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/mamba/lib/python3.10/site-packages (from contextily) (3.8.2)\n",
      "Collecting mercantile (from contextily)\n",
      "  Downloading mercantile-1.2.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pillow in /opt/mamba/lib/python3.10/site-packages (from contextily) (10.1.0)\n",
      "Collecting rasterio (from contextily)\n",
      "  Downloading rasterio-1.3.9-cp310-cp310-manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: requests in /opt/mamba/lib/python3.10/site-packages (from contextily) (2.31.0)\n",
      "Requirement already satisfied: joblib in /opt/mamba/lib/python3.10/site-packages (from contextily) (1.3.2)\n",
      "Requirement already satisfied: xyzservices in /opt/mamba/lib/python3.10/site-packages (from contextily) (2023.10.1)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy->contextily)\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m911.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->contextily) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->contextily) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->contextily) (4.45.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->contextily) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->contextily) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->contextily) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->contextily) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->contextily) (2.8.2)\n",
      "Requirement already satisfied: click>=3.0 in /opt/mamba/lib/python3.10/site-packages (from mercantile->contextily) (8.1.7)\n",
      "Collecting affine (from rasterio->contextily)\n",
      "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: attrs in /opt/mamba/lib/python3.10/site-packages (from rasterio->contextily) (23.1.0)\n",
      "Requirement already satisfied: certifi in /opt/mamba/lib/python3.10/site-packages (from rasterio->contextily) (2023.11.17)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/mamba/lib/python3.10/site-packages (from rasterio->contextily) (0.7.2)\n",
      "Collecting snuggs>=1.4.1 (from rasterio->contextily)\n",
      "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: click-plugins in /opt/mamba/lib/python3.10/site-packages (from rasterio->contextily) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /opt/mamba/lib/python3.10/site-packages (from rasterio->contextily) (68.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.10/site-packages (from requests->contextily) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.10/site-packages (from requests->contextily) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.10/site-packages (from requests->contextily) (1.26.18)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->contextily) (1.16.0)\n",
      "Downloading contextily-1.4.0-py3-none-any.whl (16 kB)\n",
      "Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 kB\u001b[0m \u001b[31m960.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading rasterio-1.3.9-cp310-cp310-manylinux2014_x86_64.whl (20.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m733.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: snuggs, mercantile, geographiclib, affine, rasterio, geopy, contextily\n",
      "Successfully installed affine-2.4.0 contextily-1.4.0 geographiclib-2.0 geopy-2.4.1 mercantile-1.2.1 rasterio-1.3.9 snuggs-1.4.7\n",
      "Requirement already satisfied: geopandas in /opt/mamba/lib/python3.10/site-packages (0.14.1)\n",
      "Requirement already satisfied: fiona>=1.8.21 in /opt/mamba/lib/python3.10/site-packages (from geopandas) (1.9.3)\n",
      "Requirement already satisfied: packaging in /opt/mamba/lib/python3.10/site-packages (from geopandas) (23.1)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/mamba/lib/python3.10/site-packages (from geopandas) (2.1.3)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /opt/mamba/lib/python3.10/site-packages (from geopandas) (3.6.1)\n",
      "Requirement already satisfied: shapely>=1.8.0 in /opt/mamba/lib/python3.10/site-packages (from geopandas) (2.0.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/mamba/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (23.1.0)\n",
      "Requirement already satisfied: certifi in /opt/mamba/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (2023.11.17)\n",
      "Requirement already satisfied: click~=8.0 in /opt/mamba/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/mamba/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/mamba/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
      "Requirement already satisfied: munch>=2.3.2 in /opt/mamba/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (4.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/mamba/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/mamba/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/mamba/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/mamba/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n",
      "Collecting pygeos\n",
      "  Downloading pygeos-0.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13 in /opt/mamba/lib/python3.10/site-packages (from pygeos) (1.26.2)\n",
      "Installing collected packages: pygeos\n",
      "Successfully installed pygeos-0.14\n",
      "Collecting topojson\n",
      "  Downloading topojson-1.7-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy in /opt/mamba/lib/python3.10/site-packages (from topojson) (1.26.2)\n",
      "Requirement already satisfied: shapely in /opt/mamba/lib/python3.10/site-packages (from topojson) (2.0.2)\n",
      "Requirement already satisfied: packaging in /opt/mamba/lib/python3.10/site-packages (from topojson) (23.1)\n",
      "Downloading topojson-1.7-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: topojson\n",
      "Successfully installed topojson-1.7\n"
     ]
    }
   ],
   "source": [
    "# Installation des packages\n",
    "\n",
    "!pip install -q lxml\n",
    "!pip install webdriver-manager\n",
    "!pip install BeautifulSoup4\n",
    "!pip install pandas fiona shapely pyproj rtree # à faire obligatoirement en premier pour utiliser rtree ou pygeos pour les jointures spatiales\n",
    "!pip install contextily\n",
    "!pip install geopandas\n",
    "!pip install pygeos\n",
    "!pip install topojson\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import bs4\n",
    "import lxml\n",
    "import pandas as pd\n",
    "import urllib\n",
    "\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c464f43b-8444-41a1-989e-7b21ec0d6fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2234e2-1114-46a9-9dbb-4b945c4e6fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupere les données de la conso totale d'energie par département, sur le site opendatasoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9340c7fd-81d6-4227-90e1-fc7341a28d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_departement</th>\n",
       "      <th>libelle_departement</th>\n",
       "      <th>consototale</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>Ain</td>\n",
       "      <td>9.921409e+06</td>\n",
       "      <td>{'type': 'Feature', 'geometry': {'coordinates'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02</td>\n",
       "      <td>Aisne</td>\n",
       "      <td>8.628880e+06</td>\n",
       "      <td>{'type': 'Feature', 'geometry': {'coordinates'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2A</td>\n",
       "      <td>Corse-du-Sud</td>\n",
       "      <td>1.008356e+06</td>\n",
       "      <td>{'type': 'Feature', 'geometry': {'coordinates'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2B</td>\n",
       "      <td>Haute-Corse</td>\n",
       "      <td>1.003554e+06</td>\n",
       "      <td>{'type': 'Feature', 'geometry': {'coordinates'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03</td>\n",
       "      <td>Allier</td>\n",
       "      <td>6.912756e+06</td>\n",
       "      <td>{'type': 'Feature', 'geometry': {'coordinates'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code_departement libelle_departement   consototale  \\\n",
       "0               01                 Ain  9.921409e+06   \n",
       "1               02               Aisne  8.628880e+06   \n",
       "2               2A        Corse-du-Sud  1.008356e+06   \n",
       "3               2B         Haute-Corse  1.003554e+06   \n",
       "4               03              Allier  6.912756e+06   \n",
       "\n",
       "                                                geom  \n",
       "0  {'type': 'Feature', 'geometry': {'coordinates'...  \n",
       "1  {'type': 'Feature', 'geometry': {'coordinates'...  \n",
       "2  {'type': 'Feature', 'geometry': {'coordinates'...  \n",
       "3  {'type': 'Feature', 'geometry': {'coordinates'...  \n",
       "4  {'type': 'Feature', 'geometry': {'coordinates'...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création de l'url de l'API\n",
    "\n",
    "root_api_1 = \"https://odre.opendatasoft.com\"\n",
    "url_api_1 = root_api_1+\"/api/explore/v2.1/catalog/datasets/conso-departement-annuelle/records?select=code_departement%2C%20libelle_departement%2C%20consototale%2C%20geom&where=annee%20%3D%20date%272021%27&order_by=code_departement&limit=99&exclude=libelle_departement%3A971%2C972%2C973%2C974&refine=annee%3A%222021%22\"\n",
    "\n",
    "# Récupération des données\n",
    "\n",
    "req = requests.get(url_api_1)\n",
    "conso_energie = req.json()\n",
    "\n",
    "# Extraire la liste de résultats du dictionnaire\n",
    "results = conso_energie.get('results', [])\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# On choisit les variables\n",
    "table_conso_totale = df[['code_departement', 'libelle_departement', 'consototale','geom']]\n",
    "\n",
    "# Affichage de la table\n",
    "table_conso_totale.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e69da9-d552-4ea9-afdf-40b4b6cd178d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9352ab1-c54f-404e-a50c-99e35de2874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupere les données de température par département, sur le site opendatasoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf638de5-c8b3-4797-b147-a3b30c0d0046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notre jeu de donnée nous donne la température quotidienne dans chaque département. \n",
    "# Ne prendre qu'un seul relevé de température augmente énormément la variance de la prédiction si on introduit la température dans le modèle\n",
    "# On propose donc de récupérer les relevés de températures moyen à chaque 1er du mois, et d'en faire une moyenne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4dfcf8b-7648-40f2-aa42-eb9bd4b726cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_obs</th>\n",
       "      <th>code_insee_departement</th>\n",
       "      <th>departement</th>\n",
       "      <th>tmoy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>01</td>\n",
       "      <td>Ain</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>02</td>\n",
       "      <td>Aisne</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2A</td>\n",
       "      <td>Corse-du-Sud</td>\n",
       "      <td>8.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2B</td>\n",
       "      <td>Haute-Corse</td>\n",
       "      <td>9.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>03</td>\n",
       "      <td>Allier</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_obs code_insee_departement   departement  tmoy\n",
       "0  2021-01-01                     01           Ain  1.50\n",
       "1  2021-01-01                     02         Aisne  2.15\n",
       "2  2021-01-01                     2A  Corse-du-Sud  8.71\n",
       "3  2021-01-01                     2B   Haute-Corse  9.12\n",
       "4  2021-01-01                     03        Allier  2.45"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On test pour la table des températures du mois de janvier\n",
    "\n",
    "root_api = \"https://odre.opendatasoft.com\"\n",
    "url_api_jan = root_api+\"/api/explore/v2.1/catalog/datasets/temperature-quotidienne-departementale/records?select=date_obs%2Ccode_insee_departement%2Cdepartement%2Ctmoy&where=date_obs%3Ddate'2021-01-01'&order_by=code_insee_departement&limit=99&refine=date_obs%3A%222021%22\"\n",
    "\n",
    "req = requests.get(url_api_jan)\n",
    "temp_jan = req.json()\n",
    "results = temp_jan.get('results', [])\n",
    "df = pd.DataFrame(results)\n",
    "df = df[['date_obs', 'code_insee_departement', 'departement','tmoy']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d51ea338-1b5e-4246-8f9c-b283cf4741e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On essaye d'automatiser le processus\n",
    "\n",
    "liste_url=[]\n",
    "for i in range(1, 13):\n",
    "    date_str = f\"2021-{i:02d}-01\"  # Utilisation de :02d pour formater i avec deux chiffres\n",
    "    url_api = f\"{root_api}/api/explore/v2.1/catalog/datasets/temperature-quotidienne-departementale/records?select=date_obs%2Ccode_insee_departement%2Cdepartement%2Ctmoy&where=date_obs%3Ddate'{date_str}'&order_by=code_insee_departement&limit=99&refine=date_obs%3A%222021%22\"\n",
    "    liste_url.append(url_api)\n",
    "\n",
    "liste_tab=[]\n",
    "for url_api in liste_url:\n",
    "    req = requests.get(url_api)\n",
    "    temp = req.json()\n",
    "    results = temp.get('results', [])\n",
    "    df = pd.DataFrame(results)\n",
    "    df = df[['date_obs', 'code_insee_departement', 'departement','tmoy']]\n",
    "    liste_tab.append(df)\n",
    "\n",
    "# Il reste à fusionner tous les tableaux, et calculer la moyenne des températures moyennes quotidiennes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac826ed-9ef0-4676-af9d-05d9b551cb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e6a92d-1d16-4e49-85a0-80d6028ddfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af965e24-3096-475c-9cf9-1be861de0d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a3734-d775-4da0-9998-8fe2a9c3e237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644401db-57e4-4eec-bac0-f488d0fa43ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff12d923-e69f-4285-aae4-b7eb832e85b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webscrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751f9cf0-53ba-402a-ab59-37bea392aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code département, département et population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9eee38f8-3bb0-4227-afea-29b0e87b55b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous avons besoin de scraper la donnée \"population\" sur chaque page Wikipédia des départements, et pour cela, nous devons obtenir les URL de chaque page. \n",
    "# Ainsi, nous créons une liste qui recense tous les URL nécessaires pour accéder à chaque page Wikipédia et extraire la donnée de population.\n",
    "\n",
    "url_dep = \"https://fr.wikipedia.org/wiki/D%C3%A9partement_fran%C3%A7ais\"\n",
    "text_dep = request.urlopen(url_dep).read()\n",
    "page_dep = bs4.BeautifulSoup(text_dep, 'lxml')\n",
    "tableau_dep = page_dep.find('div', {'class':'colonnes'})\n",
    "lignes_dep = tableau_dep.find_all('li')\n",
    "\n",
    "list_url=[]\n",
    "for i in range(len(lignes_dep)):\n",
    "    if re.search(r'href=\"([^\"]*)\"', str(lignes_dep[i])).group(1) not in [\"#cite_note-collectivitésOM-178\",'/wiki/Guadeloupe','/wiki/La_R%C3%A9union'] :\n",
    "        num_dep = lignes_dep[i].find('code').text.strip()\n",
    "        list_url.append([\"https://fr.wikipedia.org\"+re.search(r'href=\"([^\"]*)\"', str(lignes_dep[i])).group(1),num_dep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ea3d2f0-97e4-4946-8559-411af7f531b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous automatisons le webscraping d'une page Wikipédia, et chaque résultat est stocké dans un dictionnaire.\n",
    "\n",
    "dico_dep = dict()\n",
    "k=1\n",
    "for url in list_url:\n",
    "    text = request.urlopen(url[0]).read()\n",
    "    page = bs4.BeautifulSoup(text, 'lxml')\n",
    "    tableau = page.find('table',{'class':'infobox_v2 noarchive'})\n",
    "    tableau_body = tableau.find('tbody')\n",
    "    lignes = tableau_body.find_all('tr')\n",
    "\n",
    "    # On webscrapp le nom du département\n",
    "    \n",
    "    nom_dep_html = lignes[0].find('td')\n",
    "    nom_dep_elements = [item for item in nom_dep_html.contents if item.name != 'small'] # On retire les balises <small> qui correpondent aux sous-titres des départements (parfois traduction en breton)\n",
    "    nom_dep_nouveau_html = bs4.BeautifulSoup('', 'lxml')\n",
    "    nom_dep_nouveau_html.extend(nom_dep_elements)\n",
    "    nom_dep_texte = nom_dep_nouveau_html.text.strip()\n",
    "    nom_dep = re.sub(r'\\([^)]*\\)', '', nom_dep_texte)\n",
    "\n",
    "    # On définie le numéro du département\n",
    "    \n",
    "    num_dep = url[1]\n",
    "\n",
    "    # On webscrapp la population du département\n",
    "    \n",
    "    for ligne in lignes:\n",
    "        cols1 = ligne.find_all('th')\n",
    "        cols2 = ligne.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols1]+[elem.text.strip() for elem in cols2]\n",
    "        if cols[0]=='Population' or cols[0]=='Populationmunicipale':\n",
    "            population = re.sub(r'hab.*', '', cols[1])\n",
    "    dico_dep[num_dep] = {'nom_dep': nom_dep, 'population': population}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60a83579-3207-487d-9122-3fb62e21cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On transforme le dictionnaire en base de données\n",
    "\n",
    "data_dep = pd.DataFrame.from_dict(dico_dep,orient='index').reset_index()\n",
    "data_dep = data_dep.rename(columns={'index' : 'Numéro','nom_dep':'Nom','population':'Population'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48cecc10-92d6-4906-9419-36d7bb8e59ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numéro</th>\n",
       "      <th>Nom</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>Ain</td>\n",
       "      <td>657 856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02</td>\n",
       "      <td>Aisne</td>\n",
       "      <td>529 374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03</td>\n",
       "      <td>Allier</td>\n",
       "      <td>335 628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04</td>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>165 451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05</td>\n",
       "      <td>Hautes-Alpes</td>\n",
       "      <td>140 605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Numéro                      Nom Population\n",
       "0     01                      Ain   657 856 \n",
       "1     02                    Aisne   529 374 \n",
       "2     03                   Allier   335 628 \n",
       "3     04  Alpes-de-Haute-Provence   165 451 \n",
       "4     05             Hautes-Alpes   140 605 "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On visualise la base de donnée\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "data_dep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698a6e4f-7f95-4979-8a43-ec0cc15a78a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22fb38d-13b5-4d71-afe9-5035b2b2426e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee207cd-9347-4492-8ffa-6f79864a8f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd8aaf6-31d0-4819-a810-63ec1e60355a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b123081f-6548-4ae2-85cc-d0557d54e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pour récupérer la population sur une page wikipédia\n",
    "\n",
    "# On récupère l'url de la page wikipédia et on importe le texte HTML de la page\n",
    "\n",
    "url_Loire_Atlantique = \"https://fr.wikipedia.org/wiki/Loire-Atlantique\"\n",
    "text_Loire_Atlantique = request.urlopen(url_Loire_Atlantique).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "dff34e62-e028-42b3-b171-6829583fc14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 445 171 hab. (2020)\n"
     ]
    }
   ],
   "source": [
    "# On recherche de manière efficace les balises de la page\n",
    "population_Loire_Atlantique = 0\n",
    "page_Loire_Atlantique = bs4.BeautifulSoup(text_Loire_Atlantique, 'lxml')\n",
    "\n",
    "# On récupère le tableau souhaité\n",
    "tableau_Loire_Atlantique = page_Loire_Atlantique.find('table',{'class':'infobox_v2 noarchive'})\n",
    "\n",
    "# On extrait le corps du tableau\n",
    "tableau_Loire_Atlantique_body = tableau_Loire_Atlantique.find('tbody')\n",
    "\n",
    "# On extrait toutes les lignes\n",
    "lignes = tableau_Loire_Atlantique_body.find_all('tr')\n",
    "\n",
    "\n",
    "#On affiche uniquement le texte et on supprime le code (avec la fonction .text.strip) et on extrait la ligne population du tableau\n",
    "for ligne in lignes:\n",
    "    cols1 = ligne.find_all('th')\n",
    "    cols2 = ligne.find_all('td')\n",
    "    cols = [ele.text.strip() for ele in cols1]+[elem.text.strip() for elem in cols2]\n",
    "    if cols[0]=='Population':\n",
    "        population_Loire_Atlantique = cols[1]\n",
    "\n",
    "print(population_Loire_Atlantique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9cd6b-6c33-46d5-ad01-1efa49847bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f0eb7e-ff60-4a40-8335-766075f6ece3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ae69c-decf-4114-aca1-d4bfb9e548bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b68d5f-3387-4e67-b63a-ac309ad5a2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3d3666-661f-4842-b93d-2308211c1c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabc9a70-27c6-43a7-9ae5-2a26c23ef6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webscrapping du niveau de vie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6eb3c7f9-5a86-4d51-b606-438da590b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = request.urlopen(\"https://www.insee.fr/fr/statistiques/6436484?sommaire=6036904#tableau-figure1_radio1\").read()\n",
    "page = bs4.BeautifulSoup(text, 'lxml')\n",
    "tableau = page.find('table',{'class':'tableau-produit'})\n",
    "tableau_body = tableau.find('tbody')\n",
    "lignes = tableau_body.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "205e922a-3424-49cb-b901-cbf9d33ac5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nom</th>\n",
       "      <th>Niveau de Vie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ain</td>\n",
       "      <td>23 490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aisne</td>\n",
       "      <td>19 880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allier</td>\n",
       "      <td>20 570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alpes-Maritimes</td>\n",
       "      <td>22 300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>20 690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Nom Niveau de Vie\n",
       "0                      Ain        23 490\n",
       "1                    Aisne        19 880\n",
       "2                   Allier        20 570\n",
       "3          Alpes-Maritimes        22 300\n",
       "4  Alpes-de-Haute-Provence        20 690"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico_niveau_vie={}\n",
    "for ligne in lignes:\n",
    "    nom_dep = ligne.find('th').text.strip()\n",
    "    niveau_vie_dep = ligne.find('td').text.strip()\n",
    "    dico_niveau_vie[nom_dep] = {'Niveau de Vie': niveau_vie_dep}\n",
    "\n",
    "tableau_niveau_vie = pd.DataFrame.from_dict(dico_niveau_vie,orient='index').reset_index()\n",
    "tableau_niveau_vie = tableau_niveau_vie.rename(columns={'index':'Nom'}) \n",
    "tableau_niveau_vie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa97266-ae6d-4c11-b2f7-5a50bb9b2f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9aecf0-3b87-46bd-9856-a722ccbf6b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89b8a40-3dd8-4e89-9a29-3e1aa3243bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d78064-e83e-4802-b6b7-c24e4d8d0038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd7a904-0362-4a0e-9c6f-fea32940ab88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a94d346-063e-47ad-8934-363f27b03397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d2aa796-761e-4776-833e-918cd531b073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Webscrapping des logements vacants\n",
    "\n",
    "text_logements_vacants = request.urlopen(url_5).read()\n",
    "page_logements_vacants = bs4.BeautifulSoup(text_logements_vacants, 'lxml')\n",
    "tableau_logements_vacants = page_logements_vacants.find('table', {'id': 'tm_datatable'})\n",
    "print(tableau_logements_vacants)\n",
    "## A partir d'ici, pas sûr d'avoir récuperer la bonne partie du code HTML qui code le tableau\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d099d57b-6b8f-4843-a78d-c5856993211e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(page_logements_vacants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6a4b8a8-f3c4-450f-868b-a4747538114d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text_logements_vacants = request.urlopen(url_5).read()\n",
    "page_logements_vacants = bs4.BeautifulSoup(text_logements_vacants, 'lxml')\n",
    "print(page_logements_vacants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d9382-2f8c-472a-93dc-b2f868bdae6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c449afce-fa93-43c3-bce8-10a85b931aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab11fd2-badf-44c0-887e-c4b95957dc98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
