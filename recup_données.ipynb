{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "edd1bd22-2369-4e81-b6b8-ede4e73d9bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1 = \"https://odre.opendatasoft.com/explore/embed/dataset/conso-departement-annuelle/table/?disjunctive.libelle_departement&disjunctive.libelle_region&disjunctive.e_operateurs&disjunctive.g_operateurs&refine.annee=2021&dataChart=eyJxdWVyaWVzIjpbeyJjaGFydHMiOlt7InR5cGUiOiJjb2x1bW4iLCJmdW5jIjoiQVZHIiwieUF4aXMiOiJjb25zb3RvdGFsZSIsInNjaWVudGlmaWNEaXNwbGF5Ijp0cnVlLCJjb2xvciI6IiM2NmMyYTUifV0sInhBeGlzIjoibGliZWxsZV9kZXBhcnRlbWVudCIsIm1heHBvaW50cyI6NTAsInNvcnQiOiIiLCJjb25maWciOnsiZGF0YXNldCI6ImNvbnNvLWRlcGFydGVtZW50LWFubnVlbGxlIiwib3B0aW9ucyI6eyJkaXNqdW5jdGl2ZS5saWJlbGxlX2RlcGFydGVtZW50Ijp0cnVlLCJkaXNqdW5jdGl2ZS5saWJlbGxlX3JlZ2lvbiI6dHJ1ZSwiZGlzanVuY3RpdmUuZV9vcGVyYXRldXJzIjp0cnVlLCJkaXNqdW5jdGl2ZS5nX29wZXJhdGV1cnMiOnRydWUsInJlZmluZS5hbm5lZSI6IjIwMjEifX19XSwidGltZXNjYWxlIjoiIiwiZGlzcGxheUxlZ2VuZCI6dHJ1ZSwiYWxpZ25Nb250aCI6dHJ1ZX0%3D&location=3,17.56025,53.4375&basemap=jawg.light\"\n",
    "url_2 = \"https://www.insee.fr/fr/statistiques/6436484?sommaire=6036904#tableau-figure1_radio1\"\n",
    "url_3 = \"https://odre.opendatasoft.com/explore/dataset/temperature-quotidienne-departementale/download?format=csv&timezone=Europe/Berlin&use_labels_for_header=false\"\n",
    "url_4 = \"https://www.insee.fr/fr/statistiques/6436484?sommaire=6036904#tableau-figure1_radio1\"\n",
    "url_5 = \"https://www.observatoire-des-territoires.gouv.fr/outils/cartographie-interactive/#c=indicator&i=insee_rp_hist_1968.part_logt_vacant&s=2020&view=map9\"\n",
    "url_6 = \"https://ufe-electricite.fr/watt-the-carte/deploiement-bornes-de-recharge-en-france/dans-les-territoires/\"\n",
    "url_7 = \"https://www.carburants.org/borne-electrique/departements/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "a72c2552-19d8-4955-8778-fbb1722bfe63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in /opt/mamba/lib/python3.10/site-packages (4.0.1)\n",
      "Requirement already satisfied: requests in /opt/mamba/lib/python3.10/site-packages (from webdriver-manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/mamba/lib/python3.10/site-packages (from webdriver-manager) (1.0.0)\n",
      "Requirement already satisfied: packaging in /opt/mamba/lib/python3.10/site-packages (from webdriver-manager) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver-manager) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver-manager) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver-manager) (2023.11.17)\n",
      "Requirement already satisfied: BeautifulSoup4 in /opt/mamba/lib/python3.10/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/mamba/lib/python3.10/site-packages (from BeautifulSoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "# Installation des packages\n",
    "\n",
    "!pip install -q lxml\n",
    "!pip install webdriver-manager\n",
    "!pip install BeautifulSoup4\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import bs4\n",
    "import lxml\n",
    "import pandas as pd\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff12d923-e69f-4285-aae4-b7eb832e85b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webscrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "9eee38f8-3bb0-4227-afea-29b0e87b55b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous avons besoin de scraper la donnée \"population\" sur chaque page Wikipédia des départements, et pour cela, nous devons obtenir les URL de chaque page. \n",
    "# Ainsi, nous créons une liste qui recense tous les URL nécessaires pour accéder à chaque page Wikipédia et extraire la donnée de population.\n",
    "\n",
    "url_dep = \"https://fr.wikipedia.org/wiki/D%C3%A9partement_fran%C3%A7ais\"\n",
    "text_dep = request.urlopen(url_dep).read()\n",
    "page_dep = bs4.BeautifulSoup(text_dep, 'lxml')\n",
    "tableau_dep = page_dep.find('div', {'class':'colonnes'})\n",
    "lignes_dep = tableau_dep.find_all('li')\n",
    "\n",
    "list_url=[]\n",
    "for i in range(len(lignes_dep)):\n",
    "    if re.search(r'href=\"([^\"]*)\"', str(lignes_dep[i])).group(1) not in [\"#cite_note-collectivitésOM-178\",'/wiki/Guadeloupe','/wiki/La_R%C3%A9union'] :\n",
    "        list_url.append(\"https://fr.wikipedia.org\"+re.search(r'href=\"([^\"]*)\"', str(lignes_dep[i])).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "4ea3d2f0-97e4-4946-8559-411af7f531b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous automatisons le webscraping d'une page Wikipédia, et chaque résultat est stocké dans un dictionnaire.\n",
    "\n",
    "dico_dep = dict()\n",
    "k=1\n",
    "for url in list_url:\n",
    "    text = request.urlopen(url).read()\n",
    "    page = bs4.BeautifulSoup(text, 'lxml')\n",
    "    tableau = page.find('table',{'class':'infobox_v2 noarchive'})\n",
    "    tableau_body = tableau.find('tbody')\n",
    "    lignes = tableau_body.find_all('tr')\n",
    "    nom_dep = lignes[0].find('td').text.strip()\n",
    "    if 1 <= k <= 19:\n",
    "        num_dep = str(k)\n",
    "    elif k == 20:\n",
    "        num_dep = '2A'\n",
    "    elif k == 21:\n",
    "        num_dep = '2B'\n",
    "    else:\n",
    "        num_dep = str(k - 1)\n",
    "    k=k+1\n",
    "    for ligne in lignes:\n",
    "        cols1 = ligne.find_all('th')\n",
    "        cols2 = ligne.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols1]+[elem.text.strip() for elem in cols2]\n",
    "        if cols[0]=='Population' or cols[0]=='Populationmunicipale':\n",
    "            population = re.sub(r'hab.*', '', cols[1])\n",
    "    dico_dep[num_dep] = {'nom_dep': nom_dep, 'population': population}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "60a83579-3207-487d-9122-3fb62e21cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On transforme le dictionnaire en base de données\n",
    "\n",
    "data_dep = pandas.DataFrame.from_dict(dico_dep,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "48cecc10-92d6-4906-9419-36d7bb8e59ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nom_dep</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ain</td>\n",
       "      <td>657 856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aisne</td>\n",
       "      <td>529 374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allier</td>\n",
       "      <td>335 628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>165 451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hautes-Alpes</td>\n",
       "      <td>140 605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   nom_dep population\n",
       "1                      Ain   657 856 \n",
       "2                    Aisne   529 374 \n",
       "3                   Allier   335 628 \n",
       "4  Alpes-de-Haute-Provence   165 451 \n",
       "5             Hautes-Alpes   140 605 "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On visualise la base de donnée\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "data_dep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698a6e4f-7f95-4979-8a43-ec0cc15a78a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22fb38d-13b5-4d71-afe9-5035b2b2426e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d45bd27-fa44-475f-9083-690a72c66d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee207cd-9347-4492-8ffa-6f79864a8f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd8aaf6-31d0-4819-a810-63ec1e60355a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b123081f-6548-4ae2-85cc-d0557d54e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pour récupérer la population sur une page wikipédia\n",
    "\n",
    "# On récupère l'url de la page wikipédia et on importe le texte HTML de la page\n",
    "\n",
    "url_Loire_Atlantique = \"https://fr.wikipedia.org/wiki/Loire-Atlantique\"\n",
    "text_Loire_Atlantique = request.urlopen(url_Loire_Atlantique).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "dff34e62-e028-42b3-b171-6829583fc14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 445 171 hab. (2020)\n"
     ]
    }
   ],
   "source": [
    "# On recherche de manière efficace les balises de la page\n",
    "population_Loire_Atlantique = 0\n",
    "page_Loire_Atlantique = bs4.BeautifulSoup(text_Loire_Atlantique, 'lxml')\n",
    "\n",
    "# On récupère le tableau souhaité\n",
    "tableau_Loire_Atlantique = page_Loire_Atlantique.find('table',{'class':'infobox_v2 noarchive'})\n",
    "\n",
    "# On extrait le corps du tableau\n",
    "tableau_Loire_Atlantique_body = tableau_Loire_Atlantique.find('tbody')\n",
    "\n",
    "# On extrait toutes les lignes\n",
    "lignes = tableau_Loire_Atlantique_body.find_all('tr')\n",
    "\n",
    "\n",
    "#On affiche uniquement le texte et on supprime le code (avec la fonction .text.strip) et on extrait la ligne population du tableau\n",
    "for ligne in lignes:\n",
    "    cols1 = ligne.find_all('th')\n",
    "    cols2 = ligne.find_all('td')\n",
    "    cols = [ele.text.strip() for ele in cols1]+[elem.text.strip() for elem in cols2]\n",
    "    if cols[0]=='Population':\n",
    "        population_Loire_Atlantique = cols[1]\n",
    "\n",
    "print(population_Loire_Atlantique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9cd6b-6c33-46d5-ad01-1efa49847bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f0eb7e-ff60-4a40-8335-766075f6ece3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ae69c-decf-4114-aca1-d4bfb9e548bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b68d5f-3387-4e67-b63a-ac309ad5a2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3d3666-661f-4842-b93d-2308211c1c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d78064-e83e-4802-b6b7-c24e4d8d0038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd7a904-0362-4a0e-9c6f-fea32940ab88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a94d346-063e-47ad-8934-363f27b03397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d2aa796-761e-4776-833e-918cd531b073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Webscrapping des logements vacants\n",
    "\n",
    "text_logements_vacants = request.urlopen(url_5).read()\n",
    "page_logements_vacants = bs4.BeautifulSoup(text_logements_vacants, 'lxml')\n",
    "tableau_logements_vacants = page_logements_vacants.find('table', {'id': 'tm_datatable'})\n",
    "print(tableau_logements_vacants)\n",
    "## A partir d'ici, pas sûr d'avoir récuperer la bonne partie du code HTML qui code le tableau\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d099d57b-6b8f-4843-a78d-c5856993211e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(page_logements_vacants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6a4b8a8-f3c4-450f-868b-a4747538114d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text_logements_vacants = request.urlopen(url_5).read()\n",
    "page_logements_vacants = bs4.BeautifulSoup(text_logements_vacants, 'lxml')\n",
    "print(page_logements_vacants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d9382-2f8c-472a-93dc-b2f868bdae6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c449afce-fa93-43c3-bce8-10a85b931aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab11fd2-badf-44c0-887e-c4b95957dc98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
